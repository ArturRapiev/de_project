ETL Process for Google Analytics Data

Описание:
Этот проект предназначен для обработки и загрузки данных из Google Analytics (GA) в базу данных PostgreSQL с использованием Python, Dask и Apache Airflow для автоматизации и масштабируемости. Процесс включает в себя несколько этапов:

Загрузка и обработка данных:
Загружаются данные в формате Parquet и JSON, содержащие информацию о сессиях и хитах пользователей.
Применяются преобразования данных: удаление дубликатов, обработка пропусков, преобразование типов данных и времени.
Для обработки выбросов используется метод межквартильного размаха (IQR), который фильтрует аномальные значения.

Загрузка данных в PostgreSQL:
После обработки данные загружаются в PostgreSQL, где они могут быть использованы для дальнейшего анализа.
Для проверки наличия данных в базе используется механизм запросов по уникальным идентификаторам сессий.

Автоматизация с использованием Apache Airflow:
Процесс обработки данных автоматизируется с помощью DAG (Directed Acyclic Graph) в Apache Airflow.
Каждый DAG выполняет последовательность задач для обработки данных и их загрузки в базу.

Структура проекта:
de_dag.py: Скрипт для создания и запуска DAG в Airflow, который управляет процессом обработки данных и их загрузки.
parquet_processing.py: Скрипт для обработки данных в формате Parquet, включая загрузку данных, преобразование типов, обработку выбросов и загрузку в PostgreSQL.
json_processing.py: Скрипт для обработки данных в формате JSON с применением тех же шагов, что и для Parquet.

Зависимости:
Python 3.x
Apache Airflow
Dask
pandas
sqlalchemy
psycopg2
JSON (для обработки данных в формате JSON)
PostgreSQL

Убедитесь, что все зависимости установлены.

Конфигурация:
Параметры подключения к базе данных PostgreSQL задаются в скрипте parquet_processing.py и json_processing.py в переменной db_url.

Пример:
python
db_url = 'postgresql://airflow_db:airflow@192.168.0.106:5432/airflow_metadata?sslmode=disable'

Путь к данным и проекту задается через переменные окружения:
python
os.environ['PROJECT_PATH'] = '/path/to/your/project'
Логирование
Все действия в процессе обработки и загрузки данных логируются с помощью стандартной библиотеки logging. Логи выводятся в консоль и могут быть полезны для отслеживания ошибок и прогресса выполнения задач.

Важные примечания
Убедитесь, что ваш PostgreSQL сервер настроен и доступен для подключения.
Весь процесс обработки данных является параллельным, используя Dask для эффективной работы с большими объемами данных.
Этот проект предназначен для работы с большими объемами данных и обеспечивает масштабируемость обработки через Dask, а также автоматизацию с помощью Airflow.
